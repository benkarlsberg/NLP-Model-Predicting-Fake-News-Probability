{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, LSTM\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Activation, Flatten\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, precision_score, recall_score\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('data/all_data.csv')\n",
    "df_all = df_all[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning using imported functions\n",
    "def clean(text):\n",
    "    text = preprocessor(text)\n",
    "    stop_words = stopwords_list()\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_clean = df_all.copy()\n",
    "df_all_clean['text'] = df_all_clean['text'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save as CSV\n",
    "# df_all_clean.to_csv('../df_all_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load cleaned CSV\n",
    "# df_all_clean = pd.read_csv('../df_all_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "\n",
    "#split data into target and features, stratify to maintain class balance\n",
    "y = df_all_clean['label']\n",
    "X = df_all_clean['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20000 words used like tfidf from before default\n",
    "# padding required for LSTM to work, length being 50 max words default\n",
    "\n",
    "def preprocessing(X, y, num_words=20000, max_len=50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    padded_train = pad_sequences(train_sequences, maxlen=max_len,padding='post', truncating='post')\n",
    "    test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "    padded_test = pad_sequences(test_sequences, maxlen=max_len,\n",
    "                               padding='post',\n",
    "                               truncating='post')\n",
    "    return padded_train, padded_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocessing(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "\n",
    "#Non-trainable embeddidng layer\n",
    "model1.add(tf.keras.layers.Embedding(20000, output_dim=300))\n",
    "    \n",
    "model1.add(tf.keras.layers.LSTM(units=128, return_sequences = True))\n",
    "model1.add(tf.keras.layers.Dropout(0.2))\n",
    "model1.add(tf.keras.layers.LSTM(units=64))\n",
    "model1.add(tf.keras.layers.Dropout(0.1))\n",
    "model1.add(tf.keras.layers.Dense(units = 32 , activation = 'relu'))\n",
    "model1.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /Users/benkarlsberg/opt/anaconda3/envs/datasci/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "701/701 [==============================] - 87s 124ms/step - loss: 0.2125 - accuracy: 0.9185 - precision: 0.9751 - recall: 0.8476 - val_loss: 0.1718 - val_accuracy: 0.9335 - val_precision: 0.9796 - val_recall: 0.8766\n",
      "Epoch 2/15\n",
      "701/701 [==============================] - 85s 122ms/step - loss: 0.1335 - accuracy: 0.9430 - precision: 0.9734 - recall: 0.9029 - val_loss: 0.1626 - val_accuracy: 0.9352 - val_precision: 0.9602 - val_recall: 0.8992\n",
      "Epoch 3/15\n",
      "701/701 [==============================] - 82s 118ms/step - loss: 0.1001 - accuracy: 0.9533 - precision: 0.9561 - recall: 0.9434 - val_loss: 0.1675 - val_accuracy: 0.9283 - val_precision: 0.9091 - val_recall: 0.9414\n",
      "Epoch 4/15\n",
      "701/701 [==============================] - 83s 118ms/step - loss: 0.0818 - accuracy: 0.9618 - precision: 0.9513 - recall: 0.9680 - val_loss: 0.1973 - val_accuracy: 0.9320 - val_precision: 0.9413 - val_recall: 0.9120\n",
      "Epoch 5/15\n",
      "701/701 [==============================] - 82s 116ms/step - loss: 0.0652 - accuracy: 0.9709 - precision: 0.9597 - recall: 0.9791 - val_loss: 0.1788 - val_accuracy: 0.9333 - val_precision: 0.9271 - val_recall: 0.9312\n",
      "Epoch 6/15\n",
      "701/701 [==============================] - 81s 115ms/step - loss: 0.0529 - accuracy: 0.9771 - precision: 0.9649 - recall: 0.9869 - val_loss: 0.2018 - val_accuracy: 0.9278 - val_precision: 0.9148 - val_recall: 0.9331\n",
      "Epoch 7/15\n",
      "701/701 [==============================] - 83s 118ms/step - loss: 0.0469 - accuracy: 0.9816 - precision: 0.9718 - recall: 0.9894 - val_loss: 0.2323 - val_accuracy: 0.9292 - val_precision: 0.9183 - val_recall: 0.9321\n",
      "Epoch 8/15\n",
      "701/701 [==============================] - 86s 123ms/step - loss: 0.0405 - accuracy: 0.9847 - precision: 0.9771 - recall: 0.9906 - val_loss: 0.2210 - val_accuracy: 0.9313 - val_precision: 0.9373 - val_recall: 0.9148\n",
      "Epoch 9/15\n",
      "701/701 [==============================] - 87s 124ms/step - loss: 0.0364 - accuracy: 0.9865 - precision: 0.9793 - recall: 0.9921 - val_loss: 0.2664 - val_accuracy: 0.9311 - val_precision: 0.9307 - val_recall: 0.9219\n",
      "Epoch 10/15\n",
      "701/701 [==============================] - 86s 122ms/step - loss: 0.0294 - accuracy: 0.9890 - precision: 0.9835 - recall: 0.9931 - val_loss: 0.2748 - val_accuracy: 0.9293 - val_precision: 0.9217 - val_recall: 0.9283\n",
      "Epoch 11/15\n",
      "701/701 [==============================] - 85s 122ms/step - loss: 0.0259 - accuracy: 0.9907 - precision: 0.9870 - recall: 0.9931 - val_loss: 0.2923 - val_accuracy: 0.9260 - val_precision: 0.9230 - val_recall: 0.9190\n",
      "Epoch 12/15\n",
      "701/701 [==============================] - 86s 123ms/step - loss: 0.0207 - accuracy: 0.9928 - precision: 0.9912 - recall: 0.9935 - val_loss: 0.3305 - val_accuracy: 0.9227 - val_precision: 0.9166 - val_recall: 0.9190\n",
      "Epoch 13/15\n",
      "701/701 [==============================] - 86s 123ms/step - loss: 0.0173 - accuracy: 0.9941 - precision: 0.9927 - recall: 0.9947 - val_loss: 0.3544 - val_accuracy: 0.9297 - val_precision: 0.9372 - val_recall: 0.9112\n",
      "Epoch 14/15\n",
      "701/701 [==============================] - 87s 124ms/step - loss: 0.0133 - accuracy: 0.9957 - precision: 0.9955 - recall: 0.9954 - val_loss: 0.4020 - val_accuracy: 0.9294 - val_precision: 0.9259 - val_recall: 0.9236\n",
      "Epoch 15/15\n",
      "701/701 [==============================] - 87s 124ms/step - loss: 0.0108 - accuracy: 0.9968 - precision: 0.9963 - recall: 0.9969 - val_loss: 0.4317 - val_accuracy: 0.9283 - val_precision: 0.9419 - val_recall: 0.9030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16792ea90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, batch_size=64, epochs=15, verbose=1, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 300)         6000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         219648    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,271,169\n",
      "Trainable params: 6,271,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-7547b6253cdc>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_hat1_classes = model1.predict_classes(X_test)\n",
    "cf_matrix = confusion_matrix(y_hat1_classes, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7061,  613],\n",
       "       [ 385, 5947]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [[TP FN\n",
    "# [FP TN]]\n",
    "\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential()\n",
    "\n",
    "model2.add(tf.keras.layers.Embedding(20000, 300))\n",
    "model2.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(300)))\n",
    "model2.add(tf.keras.layers.Dense(300, activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "701/701 [==============================] - 177s 252ms/step - loss: 0.1793 - accuracy: 0.9203 - precision: 0.9486 - recall: 0.8772 - val_loss: 0.1322 - val_accuracy: 0.9396 - val_precision: 0.9751 - val_recall: 0.8941\n",
      "Epoch 2/15\n",
      "701/701 [==============================] - 175s 250ms/step - loss: 0.0893 - accuracy: 0.9570 - precision: 0.9536 - recall: 0.9547 - val_loss: 0.1443 - val_accuracy: 0.9391 - val_precision: 0.9362 - val_recall: 0.9340\n",
      "Epoch 3/15\n",
      "701/701 [==============================] - 185s 264ms/step - loss: 0.0661 - accuracy: 0.9697 - precision: 0.9629 - recall: 0.9727 - val_loss: 0.1895 - val_accuracy: 0.9305 - val_precision: 0.9144 - val_recall: 0.9399\n",
      "Epoch 4/15\n",
      "701/701 [==============================] - 180s 256ms/step - loss: 0.0486 - accuracy: 0.9786 - precision: 0.9731 - recall: 0.9816 - val_loss: 0.2217 - val_accuracy: 0.9315 - val_precision: 0.9465 - val_recall: 0.9053\n",
      "Epoch 5/15\n",
      "701/701 [==============================] - 183s 261ms/step - loss: 0.0343 - accuracy: 0.9859 - precision: 0.9830 - recall: 0.9871 - val_loss: 0.2353 - val_accuracy: 0.9284 - val_precision: 0.9106 - val_recall: 0.9397\n",
      "Epoch 6/15\n",
      "701/701 [==============================] - 185s 264ms/step - loss: 0.0218 - accuracy: 0.9910 - precision: 0.9902 - recall: 0.9905 - val_loss: 0.3036 - val_accuracy: 0.9309 - val_precision: 0.9246 - val_recall: 0.9285\n",
      "Epoch 7/15\n",
      "701/701 [==============================] - 176s 251ms/step - loss: 0.0165 - accuracy: 0.9940 - precision: 0.9937 - recall: 0.9934 - val_loss: 0.2714 - val_accuracy: 0.9316 - val_precision: 0.9216 - val_recall: 0.9338\n",
      "Epoch 8/15\n",
      "701/701 [==============================] - 185s 264ms/step - loss: 0.0105 - accuracy: 0.9961 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.3482 - val_accuracy: 0.9292 - val_precision: 0.9132 - val_recall: 0.9384\n",
      "Epoch 9/15\n",
      "701/701 [==============================] - 192s 274ms/step - loss: 0.0078 - accuracy: 0.9970 - precision: 0.9968 - recall: 0.9969 - val_loss: 0.4326 - val_accuracy: 0.9259 - val_precision: 0.9266 - val_recall: 0.9146\n",
      "Epoch 10/15\n",
      "701/701 [==============================] - 185s 264ms/step - loss: 0.0085 - accuracy: 0.9970 - precision: 0.9969 - recall: 0.9968 - val_loss: 0.3648 - val_accuracy: 0.9331 - val_precision: 0.9240 - val_recall: 0.9344\n",
      "Epoch 11/15\n",
      "701/701 [==============================] - 186s 266ms/step - loss: 0.0058 - accuracy: 0.9981 - precision: 0.9983 - recall: 0.9977 - val_loss: 0.3784 - val_accuracy: 0.9291 - val_precision: 0.9149 - val_recall: 0.9361\n",
      "Epoch 12/15\n",
      "701/701 [==============================] - 195s 279ms/step - loss: 0.0038 - accuracy: 0.9987 - precision: 0.9986 - recall: 0.9987 - val_loss: 0.4321 - val_accuracy: 0.9289 - val_precision: 0.9251 - val_recall: 0.9232\n",
      "Epoch 13/15\n",
      "701/701 [==============================] - 196s 280ms/step - loss: 0.0031 - accuracy: 0.9990 - precision: 0.9990 - recall: 0.9988 - val_loss: 0.4357 - val_accuracy: 0.9284 - val_precision: 0.9139 - val_recall: 0.9357\n",
      "Epoch 14/15\n",
      "701/701 [==============================] - 183s 260ms/step - loss: 0.0032 - accuracy: 0.9990 - precision: 0.9990 - recall: 0.9988 - val_loss: 0.4561 - val_accuracy: 0.9292 - val_precision: 0.9218 - val_recall: 0.9279\n",
      "Epoch 15/15\n",
      "701/701 [==============================] - 179s 256ms/step - loss: 0.0027 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9991 - val_loss: 0.4750 - val_accuracy: 0.9293 - val_precision: 0.9233 - val_recall: 0.9264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16a19d890>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, batch_size=64, epochs=15, verbose=1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         6000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 600)               1442400   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 7,623,001\n",
      "Trainable params: 7,623,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = model2.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931243752677424"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9217784476262245"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323170731707318"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6927,  444],\n",
       "       [ 519, 6116]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [[TP FN\n",
    "# [FP TN]]\n",
    "\n",
    "cf_matrix = confusion_matrix(y_pred_classes, y_test)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_output(text):\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    data = pad_sequences(sequences, maxlen=50)\n",
    "    predicted_val = model.predict(data)\n",
    "#     predicted_val = model.predict(data)    \n",
    "#     if predicted_val.max() > 0.5:\n",
    "#         output = 1\n",
    "#     else:\n",
    "#          output = 0\n",
    "    \n",
    "    return predicted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing an article\n",
    "\n",
    "# text_to_check = 'article here'\n",
    "# pred = get_pred_output(text_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
